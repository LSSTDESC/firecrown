---
title: "Using Firecrown to Generate Two-Point Statistics for LSST"
format: html
---

{{< include _functions.qmd >}}

## Purpose of this Document

In the tutorial [redshift distributions](inferred_zdist_generators.qmd) we illustrate the process of using Firecrown to create redshift distributions based on specified parameters describing the distributions.
Additionally, in [serializable redshift distributions](inferred_zdist_serialization.qmd) we demonstrate how to generate redshift distributions using serializable objects.
This document outlines how to use `InferredGalaxyZDist` objects to derive the two-point statistics pertinent to the Large Synoptic Survey Telescope (LSST), employing the redshift distribution outlined in the LSST Science Requirements Document (SRD).

This tutorial focuses on generating two-point statistics from scratch using metadata. For loading existing data from SACC files and applying scale cuts, see:
- [Two-Point Factory Basics](two_point_factory_basics.qmd)
- [Loading SACC Data](two_point_sacc_data.qmd)
- [Scale Cuts and Filtering](two_point_scale_cuts.qmd)

## Two-point statistics

Two-point statistics are widely used in cosmological analyses.
They provide a statistical summary of the distribution, in either real or harmonic space, of galaxies and the matter density field, or of other observables.
In Firecrown, two-point statistics are represented by the `TwoPoint` class, in the module `firecrown.likelihood.two_point`.

**Note:** This tutorial demonstrates generating two-point statistics from scratch. If you have existing data in a SACC file, see [Loading SACC Data](two_point_sacc_data.qmd) for how to extract and use it.

## Generating the LSST Year 1 Redshift Distribution Bins

Our initial step involves generating all photometric redshift bins necessary for the LSST year 1 redshift distribution.
This process is detailed [here](inferred_zdist_generators.qmd#sec-all-bins) in the tutorial on redshift distributions.
In the serialization [tutorial](inferred_zdist_serialization.qmd#sec-lsst-srd), we demonstrate how to get the LSST SRD redshift distributions.
Here we will use the LSST SRD year 1 redshift distribution to generate the two-point statistics.

```{python}
from firecrown.generators import (
    LSST_Y1_LENS_HARMONIC_BIN_COLLECTION,
    LSST_Y1_SOURCE_HARMONIC_BIN_COLLECTION,
)

count_bins = LSST_Y1_LENS_HARMONIC_BIN_COLLECTION.generate()
shear_bins = LSST_Y1_SOURCE_HARMONIC_BIN_COLLECTION.generate()
all_y1_bins = count_bins + shear_bins
```

## Generating the Two-Point Metadata

Within `firecrown.metadata_functions`, a suite of functions is available to calculate all possible two-point statistic metadata corresponding to a designated set of bins.
The data classes themselves live in `firecrown.metadata_types`.
For instance, demonstrated below is the computation of all feasible metadata tailored to the LSST year 1 redshift distribution:

```{python}

import numpy as np
from firecrown.metadata_functions import make_all_photoz_bin_combinations
from firecrown.metadata_types import TwoPointHarmonic

all_two_point_xy = make_all_photoz_bin_combinations(all_y1_bins)
ells = np.unique(np.geomspace(2, 2000, 128).astype(int))
all_two_point_cells = [TwoPointHarmonic(XY=xy, ells=ells) for xy in all_two_point_xy]

```

The code above generates the following table of two-point statistic metadata:
```{python}
# | code-fold: true
import pandas as pd
from IPython.display import Markdown

two_point_names = [
    (Cells.XY.x.bin_name, Cells.XY.y.bin_name, Cells.get_sacc_name())
    for Cells in all_two_point_cells
]
df = pd.DataFrame(two_point_names, columns=["bin-x", "bin-y", "SACC data-type"])
Markdown(df.to_markdown())
```

## Summary

You now have metadata for all LSST Year 1 two-point statistics. The key outputs are:

- **`all_y1_bins`**: Redshift distributions for all lens and source bins
- **`all_two_point_xy`**: All possible tracer pair combinations
- **`all_two_point_cells`**: Complete harmonic-space metadata (layouts)

These metadata objects contain no observational dataâ€”they describe the structure of measurements you want to analyze.

## Next Steps

To construct **[[likelihood|TwoPoint]]** objects from this metadata and compute predictions:

- **[Factory Basics](two_point_factory_basics.qmd)**: Learn how to use [[likelihood|TwoPointFactory]] to build TwoPoint objects, define systematics, and compute theory vectors
- **[Scale Cuts](two_point_scale_cuts.qmd)**: Apply physical scale cuts to restrict analysis ranges
- **[Integration Methods](two_point_integration.qmd)**: Control computation accuracy and speed
