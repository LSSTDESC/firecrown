{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f562b0e-7fe0-41ca-8760-5ed56753742c",
   "metadata": {},
   "source": [
    "# SACC file example for binned cluster analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ee68af-3079-4711-9056-36f63630e1c6",
   "metadata": {},
   "source": [
    "This demo notebook examplifies storing information for a binned cluster analysis into a sacc format. Steps are the following:\n",
    "- generate a mock cluster catalog in richness-redshift bins. This is done using NumCosmo functionalities and requires Numcosmo v>=0.17\n",
    "- store all this information using the SACC framework. We present to cases:\n",
    "    - store **number counts and mean mass** in a single SACC file;\n",
    "    - store **number counts and radial shear profile** in a single SACC file\n",
    "\n",
    "For the latter, in each richness-redshift bin, we generate a mock radial shear profile using CLMM. This is meant to correspond to the stacked shear profile in that bin.\n",
    "\n",
    "This should be straightforward to adapt to store counts, mean mass and radial profile in individual sacc file instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f10789d-5ee5-4ee4-ba3c-b4605909b22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This require Numcosmo v>=0.17\n",
    "from numcosmo_py import Nc\n",
    "from numcosmo_py import Ncm\n",
    "\n",
    "from firecrown.sacc_support import sacc\n",
    "\n",
    "os.environ[\n",
    "    \"CLMM_MODELING_BACKEND\"\n",
    "] = \"nc\"  # Need to use NumCosmo as CLMM's backend as well.\n",
    "import clmm\n",
    "from clmm import Cosmology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f59eaa4-e6f9-40f9-9497-966f81dee10b",
   "metadata": {},
   "source": [
    "## Prepare NumCosmo cosmology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fad6f65-7a43-4965-8e27-01fbc4f7afe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "H0 = 71.0\n",
    "Ob0 = 0.0448\n",
    "Odm0 = 0.22\n",
    "n_s = 0.963\n",
    "sigma8 = 0.8\n",
    "\n",
    "Ncm.cfg_init()\n",
    "# cosmo = Nc.HICosmoDEXcdm() # not (yet) supported by CLMM --> using Nc.HICosmoDECpl() instead\n",
    "cosmo = Nc.HICosmoDECpl()\n",
    "reion = Nc.HIReionCamb.new()\n",
    "prim = Nc.HIPrimPowerLaw.new()\n",
    "\n",
    "cosmo.add_submodel(reion)\n",
    "cosmo.add_submodel(prim)\n",
    "\n",
    "dist = Nc.Distance.new(2.0)\n",
    "\n",
    "tf = Nc.TransferFunc.new_from_name(\"NcTransferFuncEH\")\n",
    "\n",
    "psml = Nc.PowspecMLTransfer.new(tf)\n",
    "\n",
    "# psml = Nc.PowspecMLCBE.new ()\n",
    "psml.require_kmin(1.0e-6)\n",
    "psml.require_kmax(1.0e3)\n",
    "\n",
    "psf = Ncm.PowspecFilter.new(psml, Ncm.PowspecFilterType.TOPHAT)\n",
    "psf.set_best_lnr0()\n",
    "\n",
    "cosmo.props.H0 = H0\n",
    "cosmo.props.Omegab = Ob0\n",
    "cosmo.props.Omegac = Odm0\n",
    "\n",
    "cosmo.omega_x2omega_k()\n",
    "cosmo.param_set_by_name(\"Omegak\", 0.0)\n",
    "\n",
    "prim.props.n_SA = n_s\n",
    "\n",
    "old_amplitude = math.exp(prim.props.ln10e10ASA)\n",
    "prim.props.ln10e10ASA = math.log((sigma8 / cosmo.sigma8(psf)) ** 2 * old_amplitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7177d4b-7e34-46f6-9bdf-f11d9d0034b9",
   "metadata": {},
   "source": [
    "## Generate a mock cluster catalog using NumCosmo\n",
    "\n",
    "NumCosmo has a built-in functionality to generate mock cluster catalogs, from a given halo mass function (HMF) and with a log-normal richness-mass relation. \n",
    "- For the HMF, the code below uses the Tinker (2008) definition. \n",
    "- For the richness-mass relation, six parameters can be specified as the NumCosmo functionality allows for the mean relation and scatter of the log-normal distribution to have a linear dependences with both log(mass) and log(1+z) (that's 2 parameters and a normalisation, for both the mean relation and the scatter). \n",
    "\n",
    "Below we use the Murata et al. (2019) parameters (from their Table 1), but neglecting the quadratic dependence in redshift they use (this is inconsistent, but sufficient to generate this mock dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472f1c1a-2aa4-4f01-8988-45f958f5aed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sky area and the richness and redshift ranges\n",
    "area = 5000.0  # deg2\n",
    "lnRl = 0.0\n",
    "lnRu = 6.0\n",
    "zl = 0.2\n",
    "zu = 0.65\n",
    "\n",
    "cluster_z = Nc.ClusterRedshift.new_from_name(\n",
    "    f\"NcClusterRedshiftNodist{{'z-min': <{zl:22.15e}>, 'z-max':<{zu:22.15e}>}}\"\n",
    ")\n",
    "\n",
    "cluster_m = Nc.ClusterMass.new_from_name(\n",
    "    f\"NcClusterMassAscaso{{'M0':<{3.0e14 / 0.71:22.15e}>,'z0':<0.6>, \"\n",
    "    f\"'lnRichness-min':<{lnRl:22.15e}>, 'lnRichness-max':<{lnRu:22.15e}>}}\"\n",
    ")\n",
    "\n",
    "# mean richness-mass relation parameters\n",
    "cluster_m.param_set_by_name(\"mup0\", 3.15)  # normalisation\n",
    "cluster_m.param_set_by_name(\n",
    "    \"mup1\", 0.86 / np.log(10)\n",
    ")  # mass dependence, adapted to match the log10 definition used in NumCosmo\n",
    "cluster_m.param_set_by_name(\n",
    "    \"mup2\", -0.21 / np.log(10)\n",
    ")  # redshift dependence, adapted to match the log10 definition used in NumCosmo\n",
    "# richness-mass scatter parameter\n",
    "cluster_m.param_set_by_name(\"sigmap0\", 0.33)  # normalisation\n",
    "cluster_m.param_set_by_name(\n",
    "    \"sigmap1\", -0.08 / np.log(10)\n",
    ")  # mass dependence, adapted to match the log10 definition used in NumCosmo\n",
    "cluster_m.param_set_by_name(\n",
    "    \"sigmap2\", 0.03 / np.log(10)\n",
    ")  # redshift dependence, adapted to match the log10 definition used in NumCosmo\n",
    "\n",
    "\n",
    "# Numcosmo Mass Function\n",
    "# First, define the multiplicity function.\n",
    "mulf = Nc.MultiplicityFuncTinker.new()  # Tinker (2008)\n",
    "mulf.set_linear_interp(True)  # This reproduces the linear interpolation done in CCL\n",
    "mulf.set_mdef(Nc.MultiplicityFuncMassDef.MEAN)\n",
    "mulf.set_Delta(200)\n",
    "\n",
    "# Second, construct a filtered power spectrum\n",
    "hmf = Nc.HaloMassFunction.new(dist, psf, mulf)\n",
    "hmf.set_area_sd(area)\n",
    "\n",
    "# Cluster Abundance Obj\n",
    "ca = Nc.ClusterAbundance.new(hmf, None)\n",
    "\n",
    "# Number Counts object\n",
    "ncount = Nc.DataClusterNCount.new(ca, \"NcClusterRedshiftNodist\", \"NcClusterMassAscaso\")\n",
    "ca.prepare(cosmo, cluster_z, cluster_m)\n",
    "mset = Ncm.MSet.new_array([cosmo, cluster_z, cluster_m])\n",
    "\n",
    "rng = Ncm.RNG.seeded_new(None, 32)\n",
    "ncount.init_from_sampling(mset, area * ((np.pi / 180) ** 2), rng)\n",
    "\n",
    "ncount.catalog_save(\"ncount_rich.fits\", True)\n",
    "ncdata_fits = fits.open(\"ncount_rich.fits\")\n",
    "ncdata_data = ncdata_fits[1].data\n",
    "ncdata_Table = Table(ncdata_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c919b49-ee2a-4500-948a-d852169aa1c3",
   "metadata": {},
   "source": [
    "## SACC for number counts and mean mass in the $N_{\\rm richness} \\times N_z$ richness-redshift plane\n",
    "- count halos and compute mean mass in each bin, directly from the data generated at the previous step\n",
    "- associate a \"mock\" shear profile, generated using CLMM from the mean mass in the bin, mock diagonal inter-radial bin covariance. Very rough/quick solution to get some \"shear profile data\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2179c307-8f4f-4194-9d2f-26b9258dad54",
   "metadata": {},
   "source": [
    "### Counts and mean mass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0db89c8-f549-497f-bce8-f33b79166701",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table = ncdata_Table[ncdata_Table[\"LNM_OBS\"] > 2]\n",
    "cluster_z = data_table[\"Z_OBS\"]\n",
    "cluster_lnm = data_table[\"LNM_OBS\"]\n",
    "cluster_richness = cluster_lnm / np.log(10.0)\n",
    "cluster_logM = np.log10(np.exp(data_table[\"LNM_TRUE\"]))\n",
    "\n",
    "N_richness = 4  # number of richness bins\n",
    "N_z = 3  # number of redshift bins\n",
    "\n",
    "cluster_counts, z_edges, richness_edges, _ = stats.binned_statistic_2d(\n",
    "    cluster_z, cluster_richness, cluster_logM, \"count\", bins=[N_z, N_richness]\n",
    ")\n",
    "\n",
    "mean_logM = stats.binned_statistic_2d(\n",
    "    cluster_z,\n",
    "    cluster_richness,\n",
    "    cluster_logM,\n",
    "    \"mean\",\n",
    "    bins=[z_edges, richness_edges],\n",
    ").statistic\n",
    "\n",
    "std_logM = stats.binned_statistic_2d(\n",
    "    cluster_z, cluster_richness, cluster_logM, \"std\", bins=[z_edges, richness_edges]\n",
    ").statistic\n",
    "\n",
    "var_mean_logM = std_logM**2 / cluster_counts\n",
    "\n",
    "covariance = np.diag(\n",
    "    np.concatenate((cluster_counts.flatten(), var_mean_logM.flatten()))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950a2ae9-e433-4fcf-a125-503c17f212c4",
   "metadata": {},
   "source": [
    "### Saving to SACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3144e1f-5b5c-420c-83d5-2e7f34d447c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_count = sacc.Sacc()\n",
    "bin_z_labels = []\n",
    "bin_richness_labels = []\n",
    "\n",
    "survey_name = \"NC_mock_redshift_richness\"\n",
    "s_count.add_tracer(\"cluster_survey\", survey_name, area)\n",
    "\n",
    "for i, z_bin in enumerate(zip(z_edges[:-1], z_edges[1:])):\n",
    "    lower, upper = z_bin\n",
    "    bin_z_label = f\"bin_z_{i}\"\n",
    "    s_count.add_tracer(\"bin_z\", bin_z_label, lower, upper)\n",
    "    bin_z_labels.append(bin_z_label)\n",
    "\n",
    "for i, richness_bin in enumerate(zip(richness_edges[:-1], richness_edges[1:])):\n",
    "    lower, upper = richness_bin\n",
    "    bin_richness_label = f\"bin_rich_{i}\"\n",
    "    s_count.add_tracer(\"bin_richness\", bin_richness_label, lower, upper)\n",
    "    bin_richness_labels.append(bin_richness_label)\n",
    "\n",
    "cluster_count = sacc.standard_types.cluster_counts\n",
    "cluster_mass = sacc.standard_types.cluster_mean_log_mass\n",
    "\n",
    "counts_and_edges = zip(\n",
    "    cluster_counts.flatten(), itertools.product(bin_z_labels, bin_richness_labels)\n",
    ")\n",
    "\n",
    "# mean_logM_and_edges = zip(\n",
    "#     mean_logM.flatten(), itertools.product(bin_z_labels, bin_richness_labels)\n",
    "# )\n",
    "\n",
    "mean_logM_and_edges = zip(\n",
    "    mean_logM.flatten(), itertools.product(bin_z_labels, bin_richness_labels)\n",
    ")\n",
    "\n",
    "\n",
    "for counts, (bin_z_label, bin_richness_label) in counts_and_edges:\n",
    "    s_count.add_data_point(\n",
    "        cluster_count, (survey_name, bin_z_label, bin_richness_label), int(counts)\n",
    "    )\n",
    "\n",
    "for bin_mean_logM, (bin_z_label, bin_richness_label) in mean_logM_and_edges:\n",
    "    s_count.add_data_point(\n",
    "        cluster_mass,\n",
    "        (survey_name, bin_z_label, bin_richness_label),\n",
    "        bin_mean_logM,\n",
    "    )\n",
    "\n",
    "# Then the add the covariance and save the file\n",
    "s_count.add_covariance(covariance)\n",
    "s_count.to_canonical_order()\n",
    "s_count.save_fits(\"cluster_redshift_richness_sacc_data.fits\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36896c28-cc63-49bf-87d1-e9c7431ea4d9",
   "metadata": {},
   "source": [
    "### Loading SACC file and check contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dfb4d9-ab69-48f0-9005-f0363263d2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = sacc.Sacc.load_fits(\"./cluster_redshift_richness_sacc_data.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34090216-8645-4b69-b85d-4a5498497a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.get_data_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa582db-74f9-4b85-bc25-711644109c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193116ae-001f-4cb0-9df7-0a0694febed5",
   "metadata": {},
   "source": [
    "#### Look at covariance. \n",
    "Plotting log10 of the covariance for display purposes. The first upper left block correspond to the count covariance. \n",
    "The lower right block to the mean mass covariance. No off-diagonal terms were considered in this simple example. This is just a place holder to show how the SACC file is filled in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b1d729-d470-42b0-a679-98180c60708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.log10(s2.covariance.covmat))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961fdda8-0431-4c32-b8e5-a054a6a3e7fc",
   "metadata": {},
   "source": [
    "## SACC for number counts and shear profile in the $N_{\\rm richness} \\times N_z$ richness-redshift plane\n",
    "\n",
    "\n",
    "Rather than saving the mean mass into SACC, one may want to save the 'stacked' shear profile in a richness-redshift bin. This possible as exemplified below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57ead74-2612-459b-9b4b-4e07a8392614",
   "metadata": {},
   "source": [
    "### Prepare new sacc, filling it with counts (same as above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6226ebf5-5ced-4886-bbed-c04284043f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_count2 = sacc.Sacc()\n",
    "bin_z_labels = []\n",
    "bin_richness_labels = []\n",
    "\n",
    "survey_name = \"NC_mock_redshift_richness\"\n",
    "s_count2.add_tracer(\"cluster_survey\", survey_name, area)\n",
    "\n",
    "for i, z_bin in enumerate(zip(z_edges[:-1], z_edges[1:])):\n",
    "    lower, upper = z_bin\n",
    "    bin_z_label = f\"bin_z_{i}\"\n",
    "    s_count2.add_tracer(\"bin_z\", bin_z_label, lower, upper)\n",
    "    bin_z_labels.append(bin_z_label)\n",
    "\n",
    "for i, richness_bin in enumerate(zip(richness_edges[:-1], richness_edges[1:])):\n",
    "    lower, upper = richness_bin\n",
    "    bin_richness_label = f\"bin_rich_{i}\"\n",
    "    s_count2.add_tracer(\"bin_richness\", bin_richness_label, lower, upper)\n",
    "    bin_richness_labels.append(bin_richness_label)\n",
    "\n",
    "cluster_count = sacc.standard_types.cluster_counts\n",
    "counts_and_edges = zip(\n",
    "    cluster_counts.flatten(), itertools.product(bin_z_labels, bin_richness_labels)\n",
    ")\n",
    "for counts, (bin_z_label, bin_richness_label) in counts_and_edges:\n",
    "    s_count2.add_data_point(\n",
    "        cluster_count, (survey_name, bin_z_label, bin_richness_label), int(counts)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3decd4bb-2560-40bf-b461-b84cd7f87cd4",
   "metadata": {},
   "source": [
    "### Use CLMM to generate a mock shear profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd235d47-bbc4-4b74-9276-56aa5fac14b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting things up for CLMM\n",
    "cosmo_clmm = Cosmology()\n",
    "cosmo_clmm._init_from_cosmo(cosmo)\n",
    "moo = clmm.Modeling(massdef=\"mean\", delta_mdef=200, halo_profile_model=\"nfw\")\n",
    "moo.set_cosmo(cosmo_clmm)\n",
    "# assuming the same concentration for all masses. Not realistic, but avoid having to call a mass-concentration relation.\n",
    "moo.set_concentration(4)\n",
    "\n",
    "# we'll need the mean redshift of the clusters in the redshift bin\n",
    "mean_z = stats.binned_statistic_2d(\n",
    "    cluster_z,\n",
    "    cluster_richness,\n",
    "    cluster_z,\n",
    "    \"mean\",\n",
    "    bins=[z_edges, richness_edges],\n",
    ").statistic\n",
    "\n",
    "radius_edges = clmm.make_bins(\n",
    "    0.3, 6.0, nbins=6, method=\"evenlog10width\"\n",
    ")  # 6 radial bins log-spaced between 0.3 and 6 Mpc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37e9e68-1459-4f37-9d0c-e713535a027f",
   "metadata": {},
   "source": [
    "### Add the shear profile values to the SACC file\n",
    "\n",
    "To do so, on top of the redshift bin tracer and the richness bin tracer already used for the counts and mean mass, we add a radial bin tracer. A shear profile data point will then depend on those three tracers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c912d717-eb26-4072-b9ba-281befa7ff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_radius_labels = []\n",
    "radius_centers = []\n",
    "for i, radius_bin in enumerate(zip(radius_edges[:-1], radius_edges[1:])):\n",
    "    radius_lower, radius_upper = radius_bin\n",
    "    radius_center = np.mean(radius_edges[i : i + 1])\n",
    "    radius_centers.append(radius_center)\n",
    "    bin_radius_label = f\"bin_radius_{i}\"\n",
    "    s_count2.add_tracer(\n",
    "        \"bin_radius\", bin_radius_label, radius_lower, radius_upper, radius_center\n",
    "    )\n",
    "    bin_radius_labels.append(bin_radius_label)\n",
    "\n",
    "cluster_shear = sacc.standard_types.cluster_shear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f075780d-fc7b-48db-a925-1be98db349cd",
   "metadata": {},
   "source": [
    "Then we use CLMM to generate a mock shear profile in each richness and redshift bin, using the mean cluster mass and mean redhift in the bin as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433d8c0e-4c4c-4214-a72d-0b011f2541fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "redshifts_masses_and_edges = zip(\n",
    "    mean_z.flatten(),\n",
    "    mean_logM.flatten(),\n",
    "    itertools.product(bin_z_labels, bin_richness_labels),\n",
    ")\n",
    "for redshift, log_mass, (bin_z_label, bin_richness_label) in redshifts_masses_and_edges:\n",
    "    mass = 10**log_mass\n",
    "    moo.set_mass(mass)\n",
    "    profile = moo.eval_excess_surface_density(radius_centers, redshift)\n",
    "    for i, bin_radius_label in enumerate(bin_radius_labels):\n",
    "        s_count2.add_data_point(\n",
    "            cluster_shear,\n",
    "            (survey_name, bin_z_label, bin_richness_label, bin_radius_label),\n",
    "            profile[i],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e275694-a991-4ed1-9c82-d213b609bdfa",
   "metadata": {},
   "source": [
    "This is what the data now looks like:\n",
    "- 4 richness x 3 redshift bins \"number counts\" datapoints\n",
    "- 4 richness x 3 redshift x 6 radius bins \"shear profile\" datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04db6a66-6b33-45d7-8a7f-5ab00890523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_count2.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b641b9c2-b261-4b80-a9ad-a4b22f5255ac",
   "metadata": {},
   "source": [
    "### Santity check - plotting the shear profile for two richness bins, to check that the high richness bin as higher shear (i.e. ordering of data is OK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff31f15c-6808-4870-bc92-665d6f1299a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS0 = [\n",
    "    s_count2.get_data_points(\n",
    "        data_type=\"cluster_shear\",\n",
    "        tracers=(\n",
    "            \"NC_mock_redshift_richness\",\n",
    "            \"bin_z_1\",\n",
    "            \"bin_rich_0\",\n",
    "            f\"bin_radius_{i}\",\n",
    "        ),\n",
    "    )[0].value\n",
    "    for i in np.arange(len(radius_edges) - 1)\n",
    "]\n",
    "DS2 = [\n",
    "    s_count2.get_data_points(\n",
    "        data_type=\"cluster_shear\",\n",
    "        tracers=(\n",
    "            \"NC_mock_redshift_richness\",\n",
    "            \"bin_z_1\",\n",
    "            \"bin_rich_2\",\n",
    "            f\"bin_radius_{i}\",\n",
    "        ),\n",
    "    )[0].value\n",
    "    for i in np.arange(len(radius_edges) - 1)\n",
    "]\n",
    "r_arr = [\n",
    "    s_count2.get_tracer(f\"bin_radius_{i}\").center\n",
    "    for i in np.arange(len(radius_edges) - 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ca0b4-a743-40da-a956-1688291682cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(r_arr, DS0, label=\"bin_rich_0\", marker=\"x\")\n",
    "plt.loglog(r_arr, DS2, label=\"bin_rich_2\", marker=\"x\")\n",
    "plt.xlabel(\"R [Mpc]\")\n",
    "plt.ylabel(\"$\\Delta\\Sigma$ [M$_\\odot \\;$Mpc$^{-2}$]\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wrk",
   "language": "python",
   "name": "wrk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
